{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22711013",
   "metadata": {},
   "source": [
    "# Graded Lab: Agentic Workflows\n",
    "\n",
    "In this lab, you will build an agentic system that generates a short research report through planning, external tool usage, and feedback integration. Your workflow will involve:\n",
    "\n",
    "### Agents\n",
    "\n",
    "* **Planning Agent / Writer**: Creates an outline and coordinates tasks.\n",
    "* **Research Agent**: Gathers external information using tools like Arxiv, Tavily, and Wikipedia.\n",
    "* **Editor Agent**: Reflects on the report and provides suggestions for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc9f89",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='submission'></a>\n",
    "\n",
    "<h4 style=\"color:green; font-weight:bold;\">TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:</h4>\n",
    "\n",
    "* All cells are frozen except for the ones where you need to write your solution code or when explicitly mentioned you can interact with it.\n",
    "\n",
    "* In each exercise cell, look for comments `### START CODE HERE ###` and `### END CODE HERE ###`. These show you where to write the solution code. **Do not add or change any code that is outside these comments**.\n",
    "\n",
    "* You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
    "\n",
    "* Avoid using global variables unless you absolutely have to. The grader tests your code in an isolated environment without running all cells from the top. As a result, global variables may be unavailable when scoring your submission. Global variables that are meant to be used will be defined in UPPERCASE.\n",
    "\n",
    "* To submit your notebook for grading, first save it by clicking the 💾 icon on the top left of the page and then click on the <span style=\"background-color: red; color: white; padding: 3px 5px; font-size: 16px; border-radius: 5px;\">Submit assignment</span> button on the top right of the page.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4929dc",
   "metadata": {},
   "source": [
    "\n",
    "### Research Tools\n",
    "\n",
    "By importing `research_tools`, you gain access to several search utilities:\n",
    "\n",
    "- `research_tools.arxiv_search_tool(query)` → search academic papers from **arXiv**  \n",
    "\n",
    "  *Example:* `research_tools.arxiv_search_tool(\"neural networks for climate modeling\")`\n",
    "\n",
    "- `research_tools.tavily_search_tool(query)` → perform web searches with the **Tavily API**  \n",
    "\n",
    "  *Example:* `research_tools.tavily_search_tool(\"latest trends in sunglasses fashion\")`\n",
    "\n",
    "- `research_tools.wikipedia_search_tool(query)` → retrieve summaries from **Wikipedia**  \n",
    "\n",
    "  *Example:* `research_tools.wikipedia_search_tool(\"Ensemble Kalman Filter\")`\n",
    "\n",
    "Run the cell below to make them available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9723175",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 302,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "\n",
    "# --- Standard library \n",
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "import ast\n",
    "\n",
    "\n",
    "# --- Third-party ---\n",
    "from IPython.display import Markdown, display\n",
    "from aisuite import Client\n",
    "\n",
    "# --- Local / project ---\n",
    "import research_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf88f8b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 30
   },
   "outputs": [],
   "source": [
    "import unittests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abc8d9c",
   "metadata": {},
   "source": [
    "### Initialize client\n",
    "\n",
    "Create a shared client instance for upcoming calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e42f388",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 30,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "CLIENT = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89313f5",
   "metadata": {},
   "source": [
    "## Exercise 1: planner_agent\n",
    "\n",
    "### Objective\n",
    "Correctly set up a call to a language model (LLM) to generate a research plan.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. **Focus Areas**:\n",
    "   - Ensure `CLIENT.chat.completions.create` is correctly configured.\n",
    "   - Pass the `model` and `messages` parameters correctly:\n",
    "     - **Model**: Use `\"openai:o4-mini\"` by default.\n",
    "     - **Messages**: Set with `{\"role\": \"user\", \"content\": user_prompt}`.\n",
    "     - **Temperature**: Fixed at 1 for creative outputs.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The prompt is pre-defined and guides the LLM on task requirements.\n",
    "- Only return a formatted list of steps — no extra text.\n",
    "\n",
    "Focus on the LLM call setup to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be1add0d",
   "metadata": {
    "deletable": false,
    "height": 1033,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: planner_agent\n",
    "\n",
    "def planner_agent(topic: str, model: str = \"openai:o4-mini\") -> list[str]:\n",
    "    \"\"\"\n",
    "    Generates a plan as a Python list of steps (strings) for a research workflow.\n",
    "\n",
    "    Args:\n",
    "        topic (str): Research topic to investigate.\n",
    "        model (str): Language model to use.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of executable step strings.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Build the user prompt\n",
    "    user_prompt = f\"\"\"\n",
    "    You are a planning agent responsible for organizing a research workflow with multiple intelligent agents.\n",
    "\n",
    "    🧠 Available agents:\n",
    "    - A research agent who can search the web, Wikipedia, and arXiv.\n",
    "    - A writer agent who can draft research summaries.\n",
    "    - An editor agent who can reflect and revise the drafts.\n",
    "\n",
    "    🎯 Your job is to write a clear, step-by-step research plan **as a valid Python list**, where each step is a string.\n",
    "    Each step should be atomic, executable, and must rely only on the capabilities of the above agents.\n",
    "\n",
    "    🚫 DO NOT include irrelevant tasks like \"create CSV\", \"set up a repo\", \"install packages\", etc.\n",
    "    ✅ DO include real research-related tasks (e.g., search, summarize, draft, revise).\n",
    "    ✅ DO assume tool use is available.\n",
    "    ✅ DO NOT include explanation text — return ONLY the Python list.\n",
    "    ✅ The final step should be to generate a Markdown document containing the complete research report.\n",
    "\n",
    "    Topic: \"{topic}\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Add the user prompt to the messages list\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Call the LLM\n",
    "    response = CLIENT.chat.completions.create( \n",
    "        # Pass in the model\n",
    "        model=model,\n",
    "        # Define the messages. Remember this is meant to be a user prompt!\n",
    "        messages=messages,\n",
    "        # Keep responses creative\n",
    "        temperature=1, \n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Extract message from response\n",
    "    steps_str = response.choices[0].message.content.strip()\n",
    "\n",
    "    # Parse steps\n",
    "    steps = ast.literal_eval(steps_str)\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aede74d5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_planner_agent(planner_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14588d4c",
   "metadata": {},
   "source": [
    "## Exercise 2: research_agent\n",
    "\n",
    "### Objective\n",
    "Set up a call to a language model (LLM) to perform a research task using various tools.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "**Focus Areas**:\n",
    "\n",
    "- **Creating a Custom Prompt**:\n",
    "  - **Define the Role**: Clearly specify the role, such as \"research assistant.\"\n",
    "  - **List Available Tools** (as strings inside the prompt, not the actual functions):\n",
    "    - Use `arxiv_tool` to find academic papers.\n",
    "    - Use `tavily_tool` for general web searches.\n",
    "    - Use `wikipedia_tool` for accessing encyclopedic knowledge.\n",
    "  - **Specify the Task**: Include a placeholder in your prompt for defining the specific task that needs to be accomplished.\n",
    "  - **Include Date Information**: Add a placeholder for the current date or time to provide context.\n",
    "\n",
    "- **Creating Messages Dict**:\n",
    "  - Ensure the `messages` are correctly set with `{\"role\": \"user\", \"content\": prompt}`.\n",
    "\n",
    "- **Creating Tools List**:\n",
    "  - Create a list of tools for use, such as `research_tools.arxiv_search_tool`, `research_tools.tavily_search_tool`, and `research_tools.wikipedia_search_tool`.\n",
    "\n",
    "- **Correctly Setting the Call to the LLM**:\n",
    "  - Pass the `model`, `messages`, and `tools` parameters accurately.\n",
    "  - Set `tool_choice` to `\"auto\"` for automatic tool selection.\n",
    "  - Limit interactions with `max_turns=6`.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The function provides pre-coded blocks where you need to replace placeholder values.\n",
    "- The approach allows the LLM to use tools dynamically based on the task.\n",
    "\n",
    "Focus on accurately setting the messages, tools, and LLM call parameters to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f11f86e",
   "metadata": {
    "deletable": false,
    "height": 1135,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: research_agent\n",
    "\n",
    "def research_agent(task: str, model: str = \"openai:gpt-4o\", return_messages: bool = False):\n",
    "    \"\"\"\n",
    "    Executes a research task using tools via aisuite (no manual loop).\n",
    "    Returns either the assistant text, or (text, messages) if return_messages=True.\n",
    "    \"\"\"\n",
    "    print(\"==================================\")  \n",
    "    print(\"🔍 Research Agent\")                 \n",
    "    print(\"==================================\")\n",
    "\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Create a customizable prompt by defining the role (e.g., \"research assistant\"),\n",
    "    # listing tools (arxiv_tool, tavily_tool, wikipedia_tool) for various searches,\n",
    "    # specifying the task with a placeholder, and including a current_time placeholder.\n",
    "    prompt = f\"\"\"\n",
    "    You are a research assistant with access to multiple research tools.\n",
    "    \n",
    "    Available tools:\n",
    "    - arxiv_tool: Use this to find academic papers and research publications on arXiv.\n",
    "    - tavily_tool: Use this for general web searches and current information.\n",
    "    - wikipedia_tool: Use this to access encyclopedic knowledge and background information.\n",
    "    \n",
    "    Your task: {task}\n",
    "    \n",
    "    Current date: {datetime.now().strftime(\"%Y-%m-%d\")}\n",
    "    \n",
    "    Please conduct thorough research using the available tools and provide comprehensive findings.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the messages dict to pass to the LLM. Remember this is a user prompt!\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    # Save all of your available tools in the tools list. These can be found in the research_tools module.\n",
    "    # You can identify each tool in your list like this: \n",
    "    # research_tools.<name_of_tool>, where <name_of_tool> is replaced with the function name of the tool.\n",
    "    tools = [\n",
    "        research_tools.arxiv_search_tool,\n",
    "        research_tools.tavily_search_tool,\n",
    "        research_tools.wikipedia_search_tool\n",
    "    ]\n",
    "    \n",
    "    # Call the model with tools enabled\n",
    "    response = CLIENT.chat.completions.create(  \n",
    "        # Set the model\n",
    "        model=model,\n",
    "        # Pass in the messages. You already defined this!\n",
    "        messages=messages,\n",
    "        # Pass in the tools list. You already defined this!\n",
    "        tools=tools,\n",
    "        # Set the LLM to automatically choose the tools\n",
    "        tool_choice=\"auto\",\n",
    "        # Set the max turns to 6\n",
    "        max_turns=6\n",
    "    )  \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    print(\"✅ Output:\\n\", content)\n",
    "\n",
    "    \n",
    "    return (content, messages) if return_messages else content  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2c9a0ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "🔍 Research Agent\n",
      "==================================\n",
      "✅ Output:\n",
      " Please specify the topic or query you want me to focus on in finding key references.\n",
      "==================================\n",
      "🔍 Research Agent\n",
      "==================================\n",
      "✅ Output:\n",
      " The term \"seminal paper\" refers to texts that significantly impact and redefine research priorities, playing a critical role in guiding scholarly discourse. Two examples from arXiv highlight the breadth of research areas affected by seminal contributions. One recent paper, titled \"On non-bipartite graphs with integral signless Laplacian eigenvalues at most 6,\" authored by Semin Oh and others, delves into the classification of connected non-bipartite graphs, expanding the understanding of graph theory through the lens of signless Laplacian eigenvalues. Another example, \"Star Stability and Star Regularity for Mori Domains\" by Stefania Gabelli and Giampaolo Picozza, examines the extension of stability and Clifford regularity concepts using star operations in Noetherian and Mori domains, thereby offering advanced insights into algebraic structures. These papers, like those mentioned in resources about seminal research, emphasize the importance of seminal works in altering preconceived knowledge and methodologies across various scientific fields. For further discourse, one can refer to resources explaining the essence and identification of seminal papers, such as Mentafy's and MCPHS Library's guidelines.\n",
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_research_agent(research_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313fa83",
   "metadata": {},
   "source": [
    "## Exercise 3: writer_agent\n",
    "\n",
    "### Objective\n",
    "Set up a call to a language model (LLM) for executing writing tasks like drafting, expanding, or summarizing text.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. **Focus Areas**:\n",
    "   - **System Prompt**:\n",
    "     - Define `system_prompt` to assign the LLM the role of a writing agent focused on generating academic or technical content.\n",
    "   - **System and User Messages**:\n",
    "     - Create `system_msg` using `{\"role\": \"system\", \"content\": system_prompt}`.\n",
    "     - Create `user_msg` using `{\"role\": \"user\", \"content\": task}`.\n",
    "   - **Messages List**:\n",
    "     - Combine `system_msg` and `user_msg` into a `messages` list.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The function is designed to produce well-structured text by setting the correct prompts.\n",
    "- Temperature is set to 1.0 to allow for creative variance in the writing outputs.\n",
    "\n",
    "Ensure the system prompt and messages are defined properly to achieve a structured output from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57b34a6d",
   "metadata": {
    "deletable": false,
    "height": 574,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: writer_agent\n",
    "def writer_agent(task: str, model: str = \"openai:gpt-4o\") -> str: # @REPLACE def writer_agent(task: str, model: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Executes writing tasks, such as drafting, expanding, or summarizing text.\n",
    "    \"\"\"\n",
    "    print(\"==================================\")\n",
    "    print(\"✍️ Writer Agent\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Create the system prompt.\n",
    "    # This should assign the LLM the role of a writing agent specialized in generating well-structured academic or technical content\n",
    "    system_prompt = \"You are a professional writing agent specialized in generating well-structured academic and technical content. Your role is to produce clear, comprehensive, and well-organized text that meets high standards for research papers, technical documentation, and academic writing. Focus on clarity, accuracy, and proper structure in all your outputs.\"\n",
    "    \n",
    "    # Define the system msg by using the system_prompt and assigning the role of system\n",
    "    system_msg = {\"role\": \"system\", \"content\": system_prompt}\n",
    "    \n",
    "    # Define the user msg. In this case the user prompt should be the task passed to the function\n",
    "    user_msg = {\"role\": \"user\", \"content\": task}\n",
    "    \n",
    "    # Add both system and user messages to the messages list\n",
    "    messages = [system_msg, user_msg]\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    response = CLIENT.chat.completions.create(\n",
    "        model=model, \n",
    "        messages=messages,\n",
    "        temperature=1.0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac93f22d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "✍️ Writer Agent\n",
      "==================================\n",
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_writer_agent(writer_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6918fa15",
   "metadata": {},
   "source": [
    "## Exercise 4: editor_agent\n",
    "\n",
    "### Objective\n",
    "Configure a call to a language model (LLM) to perform editorial tasks such as reflecting, critiquing, or revising drafts.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. **Focus Areas**:\n",
    "   - **System Prompt**:\n",
    "     - Define `system_prompt` to assign the LLM the role of an editor agent whose task is to reflect on, critique, or improve drafts.\n",
    "   - **System and User Messages**:\n",
    "     - Create `system_msg` using `{\"role\": \"system\", \"content\": system_prompt}`.\n",
    "     - Create `user_msg` using `{\"role\": \"user\", \"content\": task}`.\n",
    "   - **Messages List**:\n",
    "     - Combine `system_msg` and `user_msg` into a `messages` list.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The editor agent is tailored for enhancing the quality of text by setting an appropriate role and task in the prompts.\n",
    "- Temperature is set to 0.7, balancing creativity and coherence in editorial outputs.\n",
    "\n",
    "Ensure the system prompt and messages are accurately set up to perform effective editorial tasks with the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f5f4928",
   "metadata": {
    "deletable": false,
    "height": 574,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: editor_agent\n",
    "def editor_agent(task: str, model: str = \"openai:gpt-4o\") -> str:\n",
    "    \"\"\"\n",
    "    Executes editorial tasks such as reflection, critique, or revision.\n",
    "    \"\"\"\n",
    "    print(\"==================================\")\n",
    "    print(\"🧠 Editor Agent\")\n",
    "    print(\"==================================\")\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Create the system prompt.\n",
    "    # This should assign the LLM the role of an editor agent specialized in reflecting on, critiquing, or improving existing drafts.\n",
    "    system_prompt = \"You are an expert editor agent specialized in reflecting on, critiquing, and improving existing drafts. Your role is to provide constructive feedback, identify areas for improvement, enhance clarity and coherence, ensure logical flow, and refine the quality of written content. Focus on both structural and stylistic improvements while maintaining the original intent and voice of the text.\"\n",
    "    \n",
    "    # Define the system msg by using the system_prompt and assigning the role of system\n",
    "    system_msg = {\"role\": \"system\", \"content\": system_prompt}\n",
    "    \n",
    "    # Define the user msg. In this case the user prompt should be the task passed to the function\n",
    "    user_msg = {\"role\": \"user\", \"content\": task}\n",
    "    \n",
    "    # Add both system and user messages to the messages list\n",
    "    messages = [system_msg, user_msg]\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    response = CLIENT.chat.completions.create(\n",
    "        model=model, \n",
    "        messages=messages,\n",
    "        temperature=0.7 \n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6096f973",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "🧠 Editor Agent\n",
      "==================================\n",
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_editor_agent(editor_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c98b1e",
   "metadata": {},
   "source": [
    "### 🎯 The Executor Agent\n",
    "\n",
    "The `executor_agent` manages the workflow by executing each step of a given plan. It:\n",
    "\n",
    "1. Decides **which agent** (`research_agent`, `writer_agent`, or `editor_agent`) should handle the step.\n",
    "2. Builds context from the outputs of previous steps.\n",
    "3. Sends the enriched task to the selected agent.\n",
    "4. Collects and stores the results in a shared history.\n",
    "\n",
    "👉 **Do not implement or modify this function.** It is already provided as the orchestration component of the multi-agent pipeline.\n",
    "\n",
    "Notice that `planner_agent` might return a long list of steps. Because of this, the maximum number of steps is set to a maximum of 4 to keep running time reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf2d02e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 268
   },
   "outputs": [],
   "source": [
    "agent_registry = {\n",
    "    \"research_agent\": research_agent,\n",
    "    \"editor_agent\": editor_agent,\n",
    "    \"writer_agent\": writer_agent,\n",
    "}\n",
    "\n",
    "def clean_json_block(raw: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean the contents of a JSON block that may come wrapped with Markdown backticks.\n",
    "    \"\"\"\n",
    "    raw = raw.strip()\n",
    "    if raw.startswith(\"```\"):\n",
    "        raw = re.sub(r\"^```(?:json)?\\n?\", \"\", raw)\n",
    "        raw = re.sub(r\"\\n?```$\", \"\", raw)\n",
    "    return raw.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c41493df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 1169
   },
   "outputs": [],
   "source": [
    "def executor_agent(topic, model: str = \"openai:gpt-4o\", limit_steps: bool = True):\n",
    "\n",
    "    plan_steps = planner_agent(topic)\n",
    "    max_steps = 4\n",
    "\n",
    "    if limit_steps:\n",
    "        plan_steps = plan_steps[:min(len(plan_steps), max_steps)]\n",
    "    \n",
    "    history = []\n",
    "\n",
    "    print(\"==================================\")\n",
    "    print(\"🎯 Editor Agent\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "    for i, step in enumerate(plan_steps):\n",
    "\n",
    "        agent_decision_prompt = f\"\"\"\n",
    "        You are an execution manager for a multi-agent research team.\n",
    "\n",
    "        Given the following instruction, identify which agent should perform it and extract the clean task.\n",
    "\n",
    "        Return only a valid JSON object with two keys:\n",
    "        - \"agent\": one of [\"research_agent\", \"editor_agent\", \"writer_agent\"]\n",
    "        - \"task\": a string with the instruction that the agent should follow\n",
    "\n",
    "        Only respond with a valid JSON object. Do not include explanations or markdown formatting.\n",
    "\n",
    "        Instruction: \"{step}\"\n",
    "        \"\"\"\n",
    "        response = CLIENT.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": agent_decision_prompt}],\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        raw_content = response.choices[0].message.content\n",
    "        cleaned_json = clean_json_block(raw_content)\n",
    "        agent_info = json.loads(cleaned_json)\n",
    "\n",
    "        agent_name = agent_info[\"agent\"]\n",
    "        task = agent_info[\"task\"]\n",
    "\n",
    "        context = \"\\n\".join([\n",
    "            f\"Step {j+1} executed by {a}:\\n{r}\" \n",
    "            for j, (s, a, r) in enumerate(history)\n",
    "        ])\n",
    "        enriched_task = f\"\"\"\n",
    "        You are {agent_name}.\n",
    "\n",
    "        Here is the context of what has been done so far:\n",
    "        {context}\n",
    "\n",
    "        Your next task is:\n",
    "        {task}\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"\\n🛠️ Executing with agent: `{agent_name}` on task: {task}\")\n",
    "\n",
    "        if agent_name in agent_registry:\n",
    "            output = agent_registry[agent_name](enriched_task)\n",
    "            history.append((step, agent_name, output))\n",
    "        else:\n",
    "            output = f\"⚠️ Unknown agent: {agent_name}\"\n",
    "            history.append((step, agent_name, output))\n",
    "\n",
    "        print(f\"✅ Output:\\n{output}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f00f8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "🎯 Editor Agent\n",
      "==================================\n",
      "\n",
      "🛠️ Executing with agent: `research_agent` on task: search arXiv, Wikipedia, and online resources for foundational knowledge on the ensemble Kalman filter and its applications in time series forecasting\n",
      "==================================\n",
      "🔍 Research Agent\n",
      "==================================\n",
      "✅ Output:\n",
      " ### Ensemble Kalman Filter: A Comprehensive Overview\n",
      "\n",
      "#### ArXiv Research on Ensemble Kalman Filter\n",
      "1. **Long-time Accuracy of Ensemble Kalman Filters for Chaotic and Machine-learned Dynamical Systems**  \n",
      "   - Authors: Daniel Sanz-Alonso, Nathan Waniorek  \n",
      "   - Summary: This paper discusses the long-time accuracy of ensemble Kalman filters, establishing conditions under which estimation error remains small in high-dimensional, partially-observed chaotic systems. It validates machine-learned forecast models in ensemble data assimilation.  \n",
      "   - [Read more](http://arxiv.org/abs/2412.14318v1)\n",
      "\n",
      "2. **Ensemble Kalman Filter with Perturbed Observations in Weather Forecasting and Data Assimilation**  \n",
      "   - Author: Yihua Yang  \n",
      "   - Summary: Highlights the use of ensemble Kalman filter with perturbed observations, improving performance in nonlinear systems and reducing computational time, as evidenced by experiments using the Lorenz 63 model.  \n",
      "   - [Read more](http://arxiv.org/abs/2004.04275v2)\n",
      "\n",
      "3. **On the Continuous Time Limit of the Ensemble Kalman Filter**  \n",
      "   - Authors: Theresa Lange, Wilhelm Stannat  \n",
      "   - Summary: The paper explores the continuous time limit for Ensemble Kalman Filter algorithms, providing insights into the use of continuous ensemble filtering for a better analysis of time-discrete processes.  \n",
      "   - [Read more](http://arxiv.org/abs/1901.05204v1)\n",
      "\n",
      "4. **A Multiresolution Ensemble Kalman Filter Using Wavelet Decomposition**  \n",
      "   - Authors: Kyle S. Hickmann, Humberto C. Godinez  \n",
      "   - Summary: Introduces a method using wavelet decomposition to improve data assimilation by separating scale information during forecasting, with applications including solar photospheric flux forecasting.  \n",
      "   - [Read more](http://arxiv.org/abs/1511.01935v1)\n",
      "\n",
      "5. **Forecasting Trends with Asset Prices**  \n",
      "   - Authors: Ahmed Bel Hadj Ayed, Grégoire Loeper, Frédéric Abergel  \n",
      "   - Summary: Discusses the use of Kalman filtering in asset price modeling and highlights the challenges and approach to forecasting trends in financial time series.  \n",
      "   - [Read more](http://arxiv.org/abs/1504.03934v2)\n",
      "\n",
      "#### Wikipedia Summary\n",
      "The Ensemble Kalman Filter (EnKF) is a computational algorithm that solves the Bayesian update problem, suitable for high-dimensional problems often found in geophysical models. It improves upon the classical Kalman Filter by employing a Monte Carlo method, replacing the covariance matrix with the sample covariance while assuming Gaussian distributions, providing an efficient alternative to particle filtering.\n",
      "\n",
      "- [Learn more on Wikipedia](https://en.wikipedia.org/wiki/Ensemble_Kalman_filter)\n",
      "\n",
      "#### Online Resources on Ensemble Kalman Filter\n",
      "1. **Ensemble Kalman Filter for GAN-ConvLSTM Based Long-term Forecasting Models**  \n",
      "   - Discusses the integration of EnKF in machine learning models like DCGAN and ConvLSTM to enhance long lead-time forecasts and improve real-time dynamic system predictions.  \n",
      "   - [Explore further](https://www.sciencedirect.com/science/article/pii/S1877750323000844)\n",
      "\n",
      "2. **Forecasting Electricity Prices Using Ensemble Kalman Filter**  \n",
      "   - Examines the application of EnKF in forecasting electricity prices, showing its effectiveness through confidence intervals and error metrics.  \n",
      "   - [View details](https://www.scienpress.com/Upload/JSEM/Vol%209_1_2.pdf)\n",
      "\n",
      "3. **Ensemble Kalman Filtering with One-Step-Ahead Smoothing**  \n",
      "   - Investigates enhancements of EnKF using one-step-ahead smoothing to improve data assimilation, demonstrating superior performance in the Lorenz-96 model studies.  \n",
      "   - [Read more](https://journals.ametsoc.org/view/journals/mwre/146/2/mwr-d-17-0175.1.xml)\n",
      "\n",
      "4. **A Multi-Model Ensemble Kalman Filter for Data Assimilation**  \n",
      "   - Introduces a multi-model EnKF approach for optimal data assimilation and forecasting by combining multiple models and observations.  \n",
      "   - [Explore further](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2022MS003123)\n",
      "\n",
      "5. **An Ensemble Kalman Filter for Numerical Weather Prediction**  \n",
      "   - Extends the EnKF approach for better ensemble analyses and forecasts through variational analysis techniques.  \n",
      "   - [Learn more](https://journals.ametsoc.org/view/journals/mwre/145/2/mwr-d-16-0106.1.xml)\n",
      "\n",
      "### Conclusion\n",
      "The Ensemble Kalman Filter is a versatile tool extensively used in various fields including weather forecasting, financial trend analysis, and machine learning models for dynamic systems. Its adaptability and efficiency in handling high-dimensional systems make it a valuable method for time series forecasting and data assimilation.\n",
      "✅ Output:\n",
      "### Ensemble Kalman Filter: A Comprehensive Overview\n",
      "\n",
      "#### ArXiv Research on Ensemble Kalman Filter\n",
      "1. **Long-time Accuracy of Ensemble Kalman Filters for Chaotic and Machine-learned Dynamical Systems**  \n",
      "   - Authors: Daniel Sanz-Alonso, Nathan Waniorek  \n",
      "   - Summary: This paper discusses the long-time accuracy of ensemble Kalman filters, establishing conditions under which estimation error remains small in high-dimensional, partially-observed chaotic systems. It validates machine-learned forecast models in ensemble data assimilation.  \n",
      "   - [Read more](http://arxiv.org/abs/2412.14318v1)\n",
      "\n",
      "2. **Ensemble Kalman Filter with Perturbed Observations in Weather Forecasting and Data Assimilation**  \n",
      "   - Author: Yihua Yang  \n",
      "   - Summary: Highlights the use of ensemble Kalman filter with perturbed observations, improving performance in nonlinear systems and reducing computational time, as evidenced by experiments using the Lorenz 63 model.  \n",
      "   - [Read more](http://arxiv.org/abs/2004.04275v2)\n",
      "\n",
      "3. **On the Continuous Time Limit of the Ensemble Kalman Filter**  \n",
      "   - Authors: Theresa Lange, Wilhelm Stannat  \n",
      "   - Summary: The paper explores the continuous time limit for Ensemble Kalman Filter algorithms, providing insights into the use of continuous ensemble filtering for a better analysis of time-discrete processes.  \n",
      "   - [Read more](http://arxiv.org/abs/1901.05204v1)\n",
      "\n",
      "4. **A Multiresolution Ensemble Kalman Filter Using Wavelet Decomposition**  \n",
      "   - Authors: Kyle S. Hickmann, Humberto C. Godinez  \n",
      "   - Summary: Introduces a method using wavelet decomposition to improve data assimilation by separating scale information during forecasting, with applications including solar photospheric flux forecasting.  \n",
      "   - [Read more](http://arxiv.org/abs/1511.01935v1)\n",
      "\n",
      "5. **Forecasting Trends with Asset Prices**  \n",
      "   - Authors: Ahmed Bel Hadj Ayed, Grégoire Loeper, Frédéric Abergel  \n",
      "   - Summary: Discusses the use of Kalman filtering in asset price modeling and highlights the challenges and approach to forecasting trends in financial time series.  \n",
      "   - [Read more](http://arxiv.org/abs/1504.03934v2)\n",
      "\n",
      "#### Wikipedia Summary\n",
      "The Ensemble Kalman Filter (EnKF) is a computational algorithm that solves the Bayesian update problem, suitable for high-dimensional problems often found in geophysical models. It improves upon the classical Kalman Filter by employing a Monte Carlo method, replacing the covariance matrix with the sample covariance while assuming Gaussian distributions, providing an efficient alternative to particle filtering.\n",
      "\n",
      "- [Learn more on Wikipedia](https://en.wikipedia.org/wiki/Ensemble_Kalman_filter)\n",
      "\n",
      "#### Online Resources on Ensemble Kalman Filter\n",
      "1. **Ensemble Kalman Filter for GAN-ConvLSTM Based Long-term Forecasting Models**  \n",
      "   - Discusses the integration of EnKF in machine learning models like DCGAN and ConvLSTM to enhance long lead-time forecasts and improve real-time dynamic system predictions.  \n",
      "   - [Explore further](https://www.sciencedirect.com/science/article/pii/S1877750323000844)\n",
      "\n",
      "2. **Forecasting Electricity Prices Using Ensemble Kalman Filter**  \n",
      "   - Examines the application of EnKF in forecasting electricity prices, showing its effectiveness through confidence intervals and error metrics.  \n",
      "   - [View details](https://www.scienpress.com/Upload/JSEM/Vol%209_1_2.pdf)\n",
      "\n",
      "3. **Ensemble Kalman Filtering with One-Step-Ahead Smoothing**  \n",
      "   - Investigates enhancements of EnKF using one-step-ahead smoothing to improve data assimilation, demonstrating superior performance in the Lorenz-96 model studies.  \n",
      "   - [Read more](https://journals.ametsoc.org/view/journals/mwre/146/2/mwr-d-17-0175.1.xml)\n",
      "\n",
      "4. **A Multi-Model Ensemble Kalman Filter for Data Assimilation**  \n",
      "   - Introduces a multi-model EnKF approach for optimal data assimilation and forecasting by combining multiple models and observations.  \n",
      "   - [Explore further](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2022MS003123)\n",
      "\n",
      "5. **An Ensemble Kalman Filter for Numerical Weather Prediction**  \n",
      "   - Extends the EnKF approach for better ensemble analyses and forecasts through variational analysis techniques.  \n",
      "   - [Learn more](https://journals.ametsoc.org/view/journals/mwre/145/2/mwr-d-16-0106.1.xml)\n",
      "\n",
      "### Conclusion\n",
      "The Ensemble Kalman Filter is a versatile tool extensively used in various fields including weather forecasting, financial trend analysis, and machine learning models for dynamic systems. Its adaptability and efficiency in handling high-dimensional systems make it a valuable method for time series forecasting and data assimilation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🛠️ Executing with agent: `research_agent` on task: collect and store key research papers and articles on the ensemble Kalman filter methodology\n",
      "==================================\n",
      "🔍 Research Agent\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "# If you want to see the full workflow without limiting the number of steps. Set limit_steps to False\n",
    "# Keep in mind this could take more than 10 minutes to complete\n",
    "executor_history = executor_agent(\"The ensemble Kalman filter for time series forecasting\", limit_steps=True)\n",
    "\n",
    "md = executor_history[-1][-1].strip(\"`\")  \n",
    "display(Markdown(md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ccebe7",
   "metadata": {},
   "source": [
    "## Check grading feedback\n",
    "\n",
    "If you have collapsed the right panel to have more screen space for your code, as shown below:\n",
    "\n",
    "<img src=\"./images/collapsed.png\" alt=\"Collapsed Image\" width=\"800\" height=\"400\"/>\n",
    "\n",
    "You can click on the left-facing arrow button (highlighted in red) to view feedback for your submission after submitting it for grading. Once expanded, it should display like this:\n",
    "\n",
    "<img src=\"./images/expanded.png\" alt=\"Expanded Image\" width=\"800\" height=\"400\"/>"
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
